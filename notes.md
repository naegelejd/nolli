# Implementation Notes

Nolli is intended to be fully re-entrant to support embedding the language
in a more commonly used language. For this reason, most functions (API or otherwise)
take some type of state `struct` as their first argument.

## Walkthrough

### Lexical Scanning/Tokenizing
Nolli's lexical scanner is very similar to that of the Lua scripting language.
The code is very easy to read and understand as it does not use any lookup tables
to implement a state machine. The `gettok` function must read one `char` at a time
from either an input file or a `char*`, constructing and returning tokens when possible.

### Parsing
Nolli uses a simple, recursive-descent, single token lookahead parser.
The parser constructs an abstract syntax tree (AST) using a family of AST creation
functions. The parser (and lexer) are not type-aware, so type names are parsed as
identifiers themselves.

The parser is capable of recovering from syntax errors by synchronizing on
semicolons to reach the end of the statement in which an error occurs.


Logic for static vs. interactive parsing:

Problem:

    `linenoise` (light-weight `readline` alternative) reads lines from the terminal
    one-at-a-time. Since statements can span multiple lines, it's often the case
    that a line entered in the terminal is not a complete statement. The parser
    needs to recognize the early EOF (NUL terminator) and tell its caller to try again
    with another line added to the input buffer.

interactive:

    start loop
    make buffer
    read a line and "append" to buffer (buffer may be empty)
    attempt to parse a SINGLE statement from the buffer
    if EOF error detected:
        the source buffer was incomplete
        read another line and append it to a buffer (and a newline character separator)
    if other errors detected, the statement needs to be RE-parsed
    end loop

file/buffer:

    if input is file, read entire file into a buffer
    repeatedly parse a SINGLE statement
    for each:
        if any error detected, the buffer has syntax errors

### Abstract Syntax Tree
The AST nodes are individually allocated on request. For large source files,
this may be slower than using memory pools to carve out AST nodes.

### Static Type-Checking
The AST generated by the parser is traversed in order to annotate expressions
with the type of the expression's intended result. This allows the next pass
to compare the expression's resulting type with the type of the identifer it
is assigned to. Assignees include local variables, function arguments, struct
members, etc.

Statement blocks are traversed using breadth-first search, while expressions
are traversed using depth-first search.

This phase must account for variable scope. This means each scope has it's own
symbol table that inherits the symbols from its parent scope's symbol table.

For every type error, an error message is generated.

This phase is also where 'type-inference' could be handled if added to the language.

### Code Generation
The type-checked AST is then traversed to generate... TBD.


## TODO

- [bug] return NULL in every parser function when an error occurs
- [bug] free `struct ast`s when errors occur during parsing
- [bug] fix broken real number parsing (exponent/mantissa/etc...)
- handle error messages in a fashion suitable for a library
- type check
- 'libify' - make sure nolli is always embeddable, re-entrant, linkable
- register-based VM (bytecode)
- garbage collector
- coroutines

## Complete

- the parser need to respect operator associativity (POW symbol is right-associative)
- the parser needs to respect operator precedence. I plan to use the
  Shunting Yard algorithm to parse expressions.
- the parser needs better error recovery (synch on semicolons, setjmp, etc.)

## Feature Ideas

- shorthand variable initialization (i.e. `name := "joe"`)
- macros/templates
- various backend code generation
    - C code
    - x86 assembly
    - JIT compilation
    - virtual machine bytecode (w/ runtime)
- use pools for allocating AST nodes?
- exceptions

## Builtin functions

id
map
foldl
foldr
filter
zip
zipWith

## Type notes

### Base Types

bool    - boolean
chr     - character
int     - integral number
real    - real number
str     - character list
lst     - homogeneous collection of values
map     - homogeneous collection of key-value pairs
tup     - heterogeneous collection of base type instances
func    - function
strm    - IO stream (reading/writing)

tup and func types are actually defined by their signature, i.e.

1. every possible grouping combination of base types is an individual `tup` type
1. every possible combination of return types and parameter types is an individual `func` type

## Keywords

This list of keywords includes builtin type names. A tool like `gperf` could generate a
perfect hash function for this list, which could then be used in a parser.

bool
char
int
real
str
list
map
file
func
struct
iface
module
import
from
alias
return
break
continue
if
else
for
in
while
true
false

## Implementation Ideas

### Grammar

weird idea example:

    Square is defined by:
        width of type int,
        height of type int.

    Shape has:
        area of type int,
        scale(int x).

    Square is a shape.

    Square's int area: return width * height
    Square's scale(int x): ...
    Square's private(): do_something()


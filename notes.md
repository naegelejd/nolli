# Implementation Notes

Nolli is intended to be fully re-entrant to support embedding the language
in a more commonly used language. For this reason, most functions (API or otherwise)
take some type of state `struct` as their first argument.

## Walkthrough

### Lexical Scanning/Tokenizing
Nolli's lexical scanner is very similar to that of the Lua scripting language.
The code is very easy to read and understand as it does not use any lookup tables
to implement a state machine. The `gettok` function must read one `char` at a time
from either an input file or a `char*`, constructing and returning tokens when possible.

### Parsing
Nolli uses a simple, recursive-descent, single token lookahead parser.
The parser constructs an abstract syntax tree (AST) using a family of AST creation
functions. The parser (and lexer) are not type-aware, so type names are parsed as
identifiers themselves.

The parser is capable of recovering from syntax errors by synchronizing on
semicolons to reach the end of the statement in which an error occurs.

### Abstract Syntax Tree
The AST nodes are individually allocated on request. For large source files,
this may be slower than using memory pools to carve out AST nodes.

### Static Type-Checking
The AST generated by the parser is traversed in order to annotate expressions
with the type of the expression's intended result. This allows the next pass
to compare the expression's resulting type with the type of the identifer it
is assigned to. Assignees include local variables, function arguments, struct
members, etc.

Statement blocks are traversed using breadth-first search, while expressions
are traversed using depth-first search.

This phase must account for variable scope. This means each scope has it's own
symbol table that inherits the symbols from its parent scope's symbol table.

For every type error, an error message is generated.

This phase is also where 'type-inference' could be handled if added to the language.

### Code Generation
The type-checked AST is then traversed to generate... TBD.

## TODO

- the parser need to respect operator associativity (POW symbol is right-associative)
- type check
- 'libify' - make sure nolli is always embeddable, re-entrant
- register-based VM (bytecode)
- garbage collector
- coroutines

## Complete

- the parser needs to respect operator precedence. I plan to use the
  Shunting Yard algorithm to parse expressions.
- the parser needs better error recovery (synch on semicolons, setjmp, etc.)

## Feature Ideas

- shorthand variable initialization (i.e. `name := "joe"`)
- macros/templates
- various backend code generation
    - C code
    - x86 assembly
    - JIT compilation
    - virtual machine bytecode (w/ runtime)
- use pools for allocating AST nodes?
- exceptions

## Builtin functions

id
map
foldl
foldr
filter
zip
zipWith

## Type notes

### Base Types

bool    - boolean
chr     - character
int     - integral number
real    - real number
str     - character list
lst     - homogeneous collection of values
map     - homogeneous collection of key-value pairs
tup     - heterogeneous collection of base type instances
func    - function
strm    - IO stream (reading/writing)

tup and func types are actually defined by their signature, i.e.

1. every possible grouping combination of base types is an individual `tup` type
1. every possible combination of return types and parameter types is an individual `func` type

## Keywords

This list of keywords includes builtin type names. A tool like `gperf` could generate a
perfect hash function for this list, which could then be used in a parser.

bool
char
int
real
str
list
map
file
func
struct
iface
module
import
from
alias
return
break
continue
if
else
for
in
while
true
false
